NOT FOR COMMERTIAL USE!!!
Written only to demonstrate the possibilities of recognition noisy digits

# Что это? 

Распознавание сильно зашумленных гауссовым шумом цифр с помощью инструментов контурного анализа.
Обучение проводилось частным случаем обучения по прецендентам[[8]](#literature-8).

Предварительная обработка осуществлялась оконными фильтрами. В общем случае был достигнут результат в 90% точности распознавания.

# Оглавление

- [Цели](#goals)
- [Общие положения](#general)
- [Алгоритм](#algo)
  - [Предварительная обработка](#algo-preprocessing)
  - [Выбор контура](#algo-contour)
  - [Контурный анализ](#algo-ca)
  - [Обучение по прецендентам](#algo-precendent)
  - [Веса для классов](#algo-weights)
  - [Корректировки и хаки](#algo-hacks)
- [Результаты экспериментов](#test)
  - [Данные и гипотезы](#test-suppose)
  - [Обучение на «жестких весах»](#test-training-hard)
  - [Проверка на «жестких весах»](#test-verification-hard)  
  - [Обучение на «мягких весах»](#test-training-soft)
  - [Проверка на «мягких весах»](#test-verification-soft)
  - [Обучение на «жестких» и проверка на «мягких» весах](#test-soft-hard)
  - [Общий результат на выборке в 3000](#test-full)
- [Инструкция по использованию](https://github.com/levabd/digit-symbol-recogniser/wiki)
  - [Основной интерфейс (обучение и распознавание)](https://github.com/levabd/digit-symbol-recogniser/wiki/%D0%9E%D1%81%D0%BD%D0%BE%D0%B2%D0%BD%D0%BE%D0%B9-%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D1%84%D0%B5%D0%B9%D1%81-(%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B8-%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5))
  - [Просмотр и редактирования прецендентов](https://github.com/levabd/digit-symbol-recogniser/wiki/%D0%9F%D1%80%D0%BE%D1%81%D0%BC%D0%BE%D1%82%D1%80-%D0%B8-%D1%80%D0%B5%D0%B4%D0%B0%D0%BA%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BF%D1%80%D0%B5%D1%86%D0%B5%D0%BD%D0%B4%D0%B5%D0%BD%D1%82%D0%BE%D0%B2)
  - [Обучение](https://github.com/levabd/digit-symbol-recogniser/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5)
- [Выводы](#conclusion)
- [Литература](#literature)
- [License](#license)

# <a name="goals"></a> Цели

Сейчас все помешаны на нейронных сетях. Хотелось доказать что нейронные сети не являются серебряной пулей.
Также хотел понять насколько эффективен контурный анализ в качестве системы распознавания. Об этом в [Выводах](#conclusion)

# <a name="general"></a> Общие положения

Для интереса были выбраны сильно зашумленные адиттивным гауссовым шумом цифры[[1]](#literature-1). Также, для усложнения процесса распознавания было принято решение проверять сразу по 5 цифр, а не по одной. Пример данных для распознавания:

![](./resources/doc/source.png?raw=true)

# <a name="algo"></a> Алгоритм


## <a name="algo-preprocessing"></a> Предварительная обработка

Для начала были вырезаны цифры из изображений по их положению на изображении. Так как в дальнейшем планировалась 
К тому же, чтобы в дальнейшем контур не соприкасался с границей. В случае

## <a name="algo-contour"></a> Выбор контура

## <a name="algo-ca"></a> Контурный анализ

## <a name="algo-precendent"></a> Обучение по прецендентам

## <a name="algo-weights"></a> Веса для классов

## <a name="algo-hacks"></a> Корректировки и хаки

# <a name="test"></a> Результаты экспериментов

## <a name="test-suppose"></a> Данные и гипотезы

Чтоб показать сходимость обучения был выбран подход:
>_Научить на 100 изображениях и проверять нераспознанные и ошибочно распознанные изображения на следующей сотне._

Под термином «обучение» подразумевается добавление в базу нового прецендента *одной цифры*. Для проверки обучения было принято придерживаться правила 80/20, 80% в качестве обучающей выборки и 20% в качестве проверочной.

## <a name="test-training-hard"></a> Обучение на «жестких весах»

Веса указаны в конфигурации ```DigitSymbolRecogniser.exe.hard.config```

                    Цифра |   0   |   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |   9
------------------------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: 
MaxACFDescriptorDeviation |   2   |   2   |   2   |   2   |    2  |   2   |   2   |   2   |   2   |   2


              Выборка | 0-100 | 101-200 | 201-300 | 301-400 | 401-500 | 501-600 | 601-700 | 701-800 | 801-900 | 901-1000 | 1001-1100 | 1101-1200
--------------------: | :---: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :------: | :-------: | :-------:
             Обучение |  225  |   129   |   90    |   78    |   72    |   74    |   69    |   57    |   57    |    52    |    49     |    52
       Нераспознанное |       |   83    |   61    |   57    |   49    |   54    |   41    |   43    |   39    |    39    |    36     |    47
Ошибочно распознанное |       |    4    |    6    |    7    |    9    |    5    |   10    |    8    |    5    |    6     |    12     |     6

*График*
![](./resources/doc/test-training-hard.png?raw=true)

>**Как видим, наблюдается:**

> - Схождение обучения к условным 50 значениям на 100 изображениях(50 прецендентам на 500 цифр)
> - Практически полное накладывание графика нераспознаного на график обучения, что весьма логично, учитывая то что обучаем мы преценденты в основном на нераспознанных изображениях
> - Небольшое увеличение ошибочно распознаных изображений. Действительно, чем больше обучаем - тем больше должно появляться ошибок

## <a name="test-verification-hard"></a> Проверка на «жестких весах»

В качестве обучающей выборки тут было взято уже существующую выборку из 1200 значений и следующие 300 значений в качестве тестовой.
Результат был таков:
* Нераспознано - 100 изображений (33%)
* Ошибочно распознано - 18 изображений (6%)

Результат вышел неудовлетворительным. бучение сходится к «50 прецендентам на 500 цифр», что слишком много. 

К тому же количество нераспознаных изображений достигает 33%, а это значит что при распознавании ищется слишком близкое соответствие обученному преценденту. В следствие этих причин было принято решение смягчить веса и повторить эксперимент.

## <a name="test-training-soft"></a> Обучение на «мягких весах»

Веса указаны в конфигурации ```DigitSymbolRecogniser.exe.soft.config```

                    Цифра |   0   |   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |   9
------------------------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: 
MaxACFDescriptorDeviation |   5   |  10   |  10   |  10   |   10  |   8   |   8   |  10   |   5   |   5


              Выборка | 0-100 | 101-200 | 201-300 | 301-400 | 401-500 | 501-600 | 601-700 | 701-800 | 801-900 | 901-1000 | 1001-1100 | 1101-1200
--------------------: | :---: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :------: | :-------: | :-------:
             Обучение |  136  |   65    |   43    |   26    |   35    |   27    |   30    |   26    |   25    |    24    |    18     |    20
       Нераспознанное |       |   57    |   42    |   26    |   34    |   25    |   34    |   26    |   23    |    23    |    16     |    20
Ошибочно распознанное |       |    3    |    8    |    7    |   10    |   12    |   12    |    7    |    8    |    9     |     7     |    13

*График*
![](./resources/doc/test-training-soft.png?raw=true)

>**Наблюдения:**

> - Схождение обучения к условным 20 значениям на 100 изображениях(20 прецендентам на 500 цифр)
> - То же накладывание графика нераспознаного на график обучения
> - Близкие значения ошибочно распознаных изображений. Это говорит о том что «мягкие» коэффициенты были взяты корректно. Не допущени излишняя мягкость.

## <a name="test-verification-soft"></a> Проверка на «мягких весах» 

В качестве обучающей выборки тут было взято уже существующую выборку из 1200 значений и следующие 300 значений в качестве тестовой.
Результат был таков:
* Нераспознано - 59 изображений (20%)
* Ошибочно распознано - 16 изображений (5%)

Результат вышел получше чем в прошлый раз но все равно неудовлетворительным. Обучение сходится к «20 прецендентам на 500 цифр», это допустимо. 

Но количество нераспознаных изображений достигает 20%, а это все еще слишком много и не то чего я хотел достичь.  

Потому было принято решение применить «жестко-мягкий» подход. Я обучу на «жестких» весах, но для проверки и распознавании буду использовать «мягкие» веса. Надеюсь это позволит получить большую обученную базу и ее разнообразие и, тем самым, достичь лучшего процента распознанных изображений.

## <a name="test-soft-hard"></a> Обучение на «жестких» и проверка на «мягких» весах

*Обучение*

              Выборка | 0-100 | 101-200 | 201-300 | 301-400 | 401-500 | 501-600 | 601-700 | 701-800 | 801-900 | 901-1000 | 1001-1100 | 1101-1200 | 1201-1300 | 1301-1400 | 1401-1500
--------------------: | :---: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :------: | :-------: | :-------: | :-------: | :-------: | :-------:
             Обучение |  225  |   129   |   90    |   78    |   72    |   74    |   69    |   57    |   57    |    52    |    49     |    52     |     41    |     42    |    35
       Нераспознанное |       |   83    |   61    |   57    |   49    |   54    |   41    |   43    |   39    |    39    |    36     |    47     |     35    |     34    |    28
Ошибочно распознанное |       |    4    |    6    |    7    |    9    |    5    |   10    |    8    |    5    |    6     |    12     |     6     |     6     |     8     |     6


*График*
![](./resources/doc/test-training-hard-soft.png?raw=true)

*Итоговое количество записанных прецендентов*

 Класс | Количество
-----: | :---------
   0   |    32
   1   |    188
   2   |    93
   3   |    142
   4   |    142
   5   |    142
   6   |    108
   7   |    135
   8   |    44
   9   |    129
  6890 |    58

Ничего нового по сравнени с обучением на «жестких» весах не видно. Количество ошибочно распознаных изображений сильно не растет, а держится приблизительно на одном уровне.
В этот было выбрано 1500 значений в качестве обучающей выборки и несколько тестовых выборок по 375 значений.

Вот результат по тестовым выборкам

              Выборка | 1501-1875 | 1876-2250 | 2251-2625 
--------------------: | :-------: | :-------: | :--------:
       Нераспознанное |     14    |     1     |    6    
Ошибочно распознанное |     22    |     22    |    20   
             Общее(%) |    9.6    |     6     |    7    
			 
_Результат вышел достачно неплохим_. Процент нераспознаного или ошибочно распознаного держится не выше 10%. 
Особенно радует тот факт что нераспознанного достаточно мало. Больше ошибочно распознанного. 
Дело в том что в выборке есть некоторое количество картинок где человек тоже не может гарантировано распознать изображение (настолько оно зашумлено).

Можно сделать вывод что «жестко-мягкий» подход хоро себя показывает на задачах классификации.

## <a name="test-full"></a> Общий результат на выборке в 3000

Для уверенности была протестирована еще выборка в 2946 изображений.

>**Общий резуольтат: Нераспознано или ошибочно распознано 294 изображений (90% точности)**
Это означает 98% точноти при распознавании отдельной цифры. 
Считаю этот результат достаточно удовлетворительным.

# <a name="conclusion"></a> Выводы

Контурный анализ, как продвинутый алгоритм ближайшего соседа (можно сравнить с методом парзеновского окна, потенциальных функций[[6]](#literature-6), алгоритм STOLP[[7]](#literature-7)) можно использовать на задачах классификации с известным и небольшим количеством классов. Желательно равновероятных, хотя есть и уловки которыми я воспользовался для избежания данной проблемы. Вопреки расхожему мнению о низкой точности метода была достигнута точность 90%. Потому, считаю что контурный анализ следует анализировать не как метод ближайшего соседа, а как самостоятельный метод классификации. Кроме того подход контурного анализа позволяет эффективно выделять сигнатуры контуров на изображении и избежать огромной размерности пространства признаков.

К преимуществам метода можно отнести:

* Отсутствие проблемы переобучения. Сам по себе контурный анализ очень эффективно справляется с выделением сигнауры изображений
* Скорость работы.
* Инвариантность к повороту обьекта.
* Простота реализации.
* Простота обучения.
* Простота модификации. Смотри [Корректировки и хаки](#algo-hacks)

Недостатками метода являются 

* Изначально классы считаются равновероятными. Но эта проблема может быть решена с помощью внедрения «весов» для каждого класса, что было сделано в данной работе.
* Сильная потребность в предварительной обработке. Разомкнутый или наоборот лишний раз сомкнутый контур очень сильно портят процесс распознавания.
* Медленная сходимость. Потребовалось около 1200 jобучений всего для 10 классов. Антилидер класс «1» с 188 обучениями.
* Сложная настройка весов (Практически ручная)
* Ручное внедрение весов для каждого класса. Делает невозможным применение метода для задач кластеризации с заранее неизвестным количеством классов.

В результате можно сказать что применять эту методику стоит если вам нужно какая-то не сильно сложная система распознавания с небольшим количеством классов(текущая задача). Для более серьезных вещей применить будет затруднительно.

# <a name="literature"></a> Литература

<a name="literature-1"></a> 1. [Рафаэл С. Гонсалес, Ричард Е. Вудс Цифровая обработка изображений, Техносфера Москва 2005 Pp 335](./resources/literature/Cifrovaya_obrabotka_izobrageniy.djvu)

<a name="literature-2"></a> 2. [Giuseppe Papari, Nicolai Petkov, and Patrizio Campisi, Artistic Edge and Corner Enhancing Smoothing, IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 16, NO. 10, OCTOBER 2007, pages 2449-2461](./resources/literature/TIP_artistic.pdf)

<a name="literature-3"></a> 3. [Shapiro, L. G. & Stockman, G. C: "Computer Vision", page 137, 150. Prentice Hall, 2001](./resources/literature/Computer-Vision-Linda-Shapiro.pdf)

<a name="literature-4"></a> 4. [Canny, J., A Computational Approach To Edge Detection, IEEE Trans. Pattern Analysis and Machine Intelligence, 8(6):679–698, 1986.](./resources/literature/canny1986.pdf)

<a name="literature-5"></a> 5. [Фурман Я.А. (ред.) Введение в контурный анализ. Приложения к обработке изображений и сигналов, М.: ФИЗМАТЛИТ, 2003](./resources/literature/Vvedenije_v_konturnyj_analiz_2003.djvu)

<a name="literature-6"></a> 6. [Айзерман М. А., Браверман Э. М., Розоноэр Л. И. Метод потенциальных функций в теории обучения машин. — М.: Наука, 1970. — 320 pp.](./resources/literature/The-method-of-potential-functions-in-machine-learning-theory.djvu)

<a name="literature-7"></a> 7. [Вапник В. Н., Червоненкис А. Я. Теория распознавания образов. — М.: Наука, 1974.](./resources/literature/Vapnik.djvu)

<a name="literature-8"></a> 8. [Воронцов К.В. Математические методы обучения по прецедентам (теория обучения машин) Pp. 43-55](./resources/literature/Voron-ML-1.pdf?raw=true)

# <a name="license"></a> Лицензия

Распространяется под [MIT license](LICENSE)
Проще говоря, как есть:)
